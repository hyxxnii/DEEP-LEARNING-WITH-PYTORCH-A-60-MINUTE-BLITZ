{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([[[1., 2.],\n",
      "         [3., 4.]],\n",
      "\n",
      "        [[5., 6.],\n",
      "         [7., 8.]]])\n"
     ]
    }
   ],
   "source": [
    "# 파이썬 리스트로부터 생성\n",
    "\n",
    "V_data = [1., 2., 3.] # 벡터\n",
    "V = torch.Tensor(V_data)\n",
    "print(V)\n",
    "\n",
    "M_data = [[1., 2., 3.,], [4., 5., 6.]] # 행렬\n",
    "M = torch.Tensor(M_data)\n",
    "print(M)\n",
    "\n",
    "T_data = [[[1.,2.], [3.,4.]], # 3차원 텐서\n",
    "        [[5.,6.], [7.,8.]]]\n",
    "\n",
    "T = torch.Tensor(T_data)\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1.0, 2.0], [3.0, 4.0]], [[5.0, 6.0], [7.0, 8.0]]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.tolist() # 반대로 파이토치 텐서 -> 파이썬 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([[[1., 2.],\n",
      "         [3., 4.]],\n",
      "\n",
      "        [[5., 6.],\n",
      "         [7., 8.]]])\n"
     ]
    }
   ],
   "source": [
    "# numpy array 객체로부터 생성\n",
    "V_data = np.array([1., 2., 3.]) # 벡터\n",
    "V = torch.Tensor(V_data) # 바로 랩핑할 수 있음\n",
    "print(V)\n",
    "\n",
    "M_data = np.array([[1., 2., 3.], [4., 5., 6]]) # 행렬\n",
    "M = torch.Tensor(M_data)\n",
    "print(M)\n",
    "\n",
    "T_data = np.array([[[1.,2.], [3.,4.]], # 3차원 텐서\n",
    "                [[5.,6.], [7.,8.]]])\n",
    "T = torch.Tensor(T_data)\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 2.],\n",
       "        [3., 4.]],\n",
       "\n",
       "       [[5., 6.],\n",
       "        [7., 8.]]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.numpy() # 반대로 파이토치 텐서 -> 넘파이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0.7576, 0.2793, 0.4031, 0.7347],\n",
      "        [0.0293, 0.7999, 0.3971, 0.7544],\n",
      "        [0.5695, 0.4388, 0.6387, 0.5247]])\n",
      "tensor([[-1.5228,  0.3817, -1.0276, -0.5631],\n",
      "        [-0.8923, -0.0583, -0.1955, -0.9656],\n",
      "        [ 0.4224,  0.2673, -0.4212, -0.5107]])\n",
      "tensor([3, 0, 4, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "# 기타 생성 방법들\n",
    "x = torch.zeros(2,3)\n",
    "print(x)\n",
    "\n",
    "x = torch.ones(2, 3)\n",
    "print(x)\n",
    "\n",
    "x = torch.rand(3, 4)\n",
    "print(x)\n",
    "\n",
    "x = torch.randn(3, 4) # 표준정규분포에서 샘플링\n",
    "print(x)  # FloatTensor가 디폴트\n",
    "\n",
    "x = torch.randperm(5) # permutation of integers from 0 to n - 1\n",
    "print(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Indexing, Slicing, Joining, Mutating Ops\n",
    "\n",
    "http://pytorch.org/docs/0.3.0/torch.html?#indexing-slicing-joining-mutating-ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.9906, 0.2885, 0.8750, 0.5059, 0.2366],\n",
      "         [0.7570, 0.2346, 0.6471, 0.3556, 0.4452],\n",
      "         [0.0193, 0.2616, 0.7713, 0.3785, 0.9980],\n",
      "         [0.9008, 0.4766, 0.1663, 0.8045, 0.6552]],\n",
      "\n",
      "        [[0.1768, 0.8248, 0.8036, 0.9434, 0.2197],\n",
      "         [0.4177, 0.4903, 0.5730, 0.1205, 0.1452],\n",
      "         [0.7720, 0.3828, 0.7442, 0.5285, 0.6642],\n",
      "         [0.6099, 0.6818, 0.7479, 0.0369, 0.7517]],\n",
      "\n",
      "        [[0.1484, 0.1227, 0.5304, 0.4148, 0.7937],\n",
      "         [0.2104, 0.0555, 0.8639, 0.4259, 0.7812],\n",
      "         [0.6607, 0.1251, 0.6004, 0.6201, 0.1652],\n",
      "         [0.2628, 0.6705, 0.5896, 0.2873, 0.3486]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3, 4, 5)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9906, 0.2885, 0.8750, 0.5059, 0.2366],\n",
       "        [0.7570, 0.2346, 0.6471, 0.3556, 0.4452],\n",
       "        [0.0193, 0.2616, 0.7713, 0.3785, 0.9980],\n",
       "        [0.9008, 0.4766, 0.1663, 0.8045, 0.6552]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0] # 직관적 인덱싱 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9906, 0.2885, 0.8750, 0.5059, 0.2366])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9906)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][0][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.index_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5009,  0.5438, -0.4057,  1.1341],\n",
      "        [-1.1115,  0.3501, -0.7703, -0.1473],\n",
      "        [ 0.6272,  1.0935,  0.0939,  1.2381]])\n",
      "tensor([0, 2])\n",
      "tensor([[ 0.5009,  0.5438, -0.4057,  1.1341],\n",
      "        [ 0.6272,  1.0935,  0.0939,  1.2381]])\n",
      "tensor([[ 0.5009, -0.4057],\n",
      "        [-1.1115, -0.7703],\n",
      "        [ 0.6272,  0.0939]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 4)\n",
    "print(x)\n",
    "\n",
    "indices = torch.LongTensor([0, 2])\n",
    "print(indices) # 선택할 index (LongTensor)\n",
    "\n",
    "print(torch.index_select(x, 0, indices)) # row 기준으로 index select\n",
    "print(torch.index_select(x, 1, indices)) # column 기준으로 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.masked_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.7687e-01, -3.1020e+00, -9.9467e-02, -7.2126e-01],\n",
      "        [ 1.2708e+00, -2.0225e-03, -1.0952e+00,  6.0165e-01],\n",
      "        [ 6.9841e-01, -8.0052e-01,  1.5381e+00,  1.4673e+00]])\n",
      "tensor([[False, False, False, False],\n",
      "        [ True, False, False,  True],\n",
      "        [ True, False,  True,  True]])\n",
      "tensor([1.2708, 0.6016, 0.6984, 1.5381, 1.4673])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 4)\n",
    "print(x)\n",
    "\n",
    "mask = x.ge(0.5) # x 텐서에서 0.5보다 크거나 같은 값 마스킹(boolean) (ByteTensor)\n",
    "print(mask)\n",
    "\n",
    "print(torch.masked_select(x, mask)) # 마스킹 된 값 선택"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.cat ➡️ concat : 두 텐서를 붙인다 (Concatentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5951, -1.5279,  1.0156, -0.2020, -1.2865],\n",
      "        [ 0.8231, -0.6101, -1.2960, -0.9434,  0.6684],\n",
      "        [ 1.1628, -0.3229,  1.8782, -0.5666,  0.4016],\n",
      "        [-0.1153,  0.3170,  0.5629,  0.8662, -0.3528],\n",
      "        [ 0.3482,  1.1371, -0.3339, -1.4724,  0.7296]])\n",
      "tensor([[-0.1312, -0.6368,  1.0429,  1.6015, -1.0735, -1.2173,  0.6472, -0.0412],\n",
      "        [ 0.4903,  1.0318, -0.5989, -0.1775, -0.5000,  0.8673, -0.2732, -0.4608]])\n"
     ]
    }
   ],
   "source": [
    "# row-wise concat\n",
    "x_1 = torch.randn(2, 5)\n",
    "y_1 = torch.randn(3, 5)\n",
    "z_1 = torch.cat([x_1, y_1]) # default: 첫 번째 차원 기준으로 (0)\n",
    "print(z_1)\n",
    "\n",
    "# column-wise concat\n",
    "x_2 = torch.randn(2, 3)\n",
    "y_2 = torch.randn(2, 5)\n",
    "z_2 = torch.cat([x_2, y_2], 1) # 두 번째 인자로 기준이 될 차원 축 선택\n",
    "print(z_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.view ➡️ reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.8336, -1.1929, -2.3065,  0.6037],\n",
      "         [ 0.1794,  0.1447, -0.3589,  0.4793],\n",
      "         [ 1.0476, -0.3176,  0.1395,  2.3403]],\n",
      "\n",
      "        [[-0.6116,  0.8160,  0.2477, -0.3867],\n",
      "         [ 0.1995,  0.7993, -0.2619,  0.1513],\n",
      "         [ 1.1982, -2.2833, -1.0130, -0.8879]]])\n",
      "tensor([[-0.8336, -1.1929, -2.3065,  0.6037,  0.1794,  0.1447, -0.3589,  0.4793,\n",
      "          1.0476, -0.3176,  0.1395,  2.3403],\n",
      "        [-0.6116,  0.8160,  0.2477, -0.3867,  0.1995,  0.7993, -0.2619,  0.1513,\n",
      "          1.1982, -2.2833, -1.0130, -0.8879]])\n",
      "tensor([[-0.8336, -1.1929, -2.3065,  0.6037,  0.1794,  0.1447, -0.3589,  0.4793,\n",
      "          1.0476, -0.3176,  0.1395,  2.3403],\n",
      "        [-0.6116,  0.8160,  0.2477, -0.3867,  0.1995,  0.7993, -0.2619,  0.1513,\n",
      "          1.1982, -2.2833, -1.0130, -0.8879]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 3, 4)\n",
    "print(x)\n",
    "print(x.view(2, 12)) # 2x12로 reshape\n",
    "print(x.view(2, -1)) # -1: 각 차원을 다 곱한 값에서 명시적인 차원수로 나눠서 추론"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.squeeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.],\n",
      "          [0.]]],\n",
      "\n",
      "\n",
      "        [[[0.],\n",
      "          [0.]]]])\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[[0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(2, 1, 2, 1)\n",
    "print(x)\n",
    "print(x.squeeze()) # 차원 size = 1인 차원을 제거 => 2x2\n",
    "print(x.squeeze(1)) # 차원 수 명시 가능 => 2x2x1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.unsqueeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0766, -0.8562, -0.7870, -0.8161,  0.5470])\n",
      "tensor([[-0.0766, -0.8562, -0.7870, -0.8161,  0.5470]])\n",
      "tensor([[-0.0766],\n",
      "        [-0.8562],\n",
      "        [-0.7870],\n",
      "        [-0.8161],\n",
      "        [ 0.5470]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(5)\n",
    "print(x)\n",
    "\n",
    "print(x.unsqueeze(0)) # squeeze의 반대 => size=1인 차원을 추가\n",
    "print(x.unsqueeze(1)) # range of [-2, 1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Match opteration\n",
    "http://pytorch.org/docs/0.3.0/torch.html?#math-operations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 7., 9.])\n",
      "tensor([5., 7., 9.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([1., 2., 3.]) \n",
    "y = torch.Tensor([4., 5., 6.])\n",
    "z = x + y # torch.add(x,y)\n",
    "print(z)\n",
    "print(torch.add(x, y))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([1, 2, 3])\n",
    "print(x.sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(32.)\n",
      "tensor(32.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([1, 2, 3])\n",
    "y = torch.Tensor([4, 5, 6])\n",
    "z = x.dot(y) # torch.dot(x, y)\n",
    "print(z)\n",
    "print(torch.dot(x, y))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4., 10., 18.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([1, 2, 3])\n",
    "y = torch.Tensor([4, 5, 6])\n",
    "z = x.mul(y)\n",
    "print(z)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mm: matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.6054, -1.3538,  2.5214],\n",
      "        [ 1.3804,  2.5942, -2.6082]])\n",
      "tensor([[-1.6054, -1.3538,  2.5214],\n",
      "        [ 1.3804,  2.5942, -2.6082]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 2)\n",
    "y = torch.randn(2, 3)\n",
    "z = x.mm(y) # torch.mm(x, y)\n",
    "print(z)\n",
    "print(torch.mm(x, y))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.)\n",
      "torch.return_types.max(\n",
      "values=tensor([2., 4.]),\n",
      "indices=tensor([1, 1]))\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1.,2.],[3.,4.]])\n",
    "print(x.max())\n",
    "print(x.max(1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Computation Graphs and Automatic Differentiation\n",
    "딥러닝 프레임워크의 가장 큰 장점인 **자동 미분 기능**을 사용하기 위해서는 `Variable`, `Parameter` 클래스로 래핑해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.], requires_grad=True)\n",
      "tensor([1., 2., 3.])\n",
      "tensor([5., 7., 9.])\n",
      "<AddBackward0 object at 0x127f06220>\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "# Variable: 텐서를 래핑한다 (autograd 기능에 의한 미분값의 필요 여부를 결정할 수 있음)\n",
    "x = Variable(torch.Tensor([1, 2, 3]), requires_grad=True)\n",
    "print(x)\n",
    "\n",
    "# Variable로 감싸준 상태에서 .data로 원래 텐서에 접근\n",
    "print(x.data)\n",
    "\n",
    "# Variable로 래핑한 다른 텐서들과도 연산 가능\n",
    "y = Variable(torch.Tensor([4, 5, 6]), requires_grad=True)\n",
    "z = torch.add(x, y)\n",
    "print(z.data)\n",
    "\n",
    "# 하지만 연산의 결과인 z는 뭔가 추가적인 정보를 알고 있음!\n",
    "print(z.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(21., grad_fn=<SumBackward0>)\n",
      "<SumBackward0 object at 0x12656c580>\n"
     ]
    }
   ],
   "source": [
    "s = z.sum()\n",
    "print(s)\n",
    "print(s.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "s.backward() # 이 값으로부터 backpropagation을 하고 싶다면 => .backward()를 call\n",
    "print(x.grad)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align='center'>\n",
    "\n",
    "$s =\\overbrace{x_0 + y_0}^{z_0} +\\overbrace{x_1 + y_1}^{z_1} + \\overbrace{x_2 + y_2}^{z_2}$\n",
    "\n",
    "$\\frac{\\partial s}{\\partial x_0}$\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable vs Parameter\n",
    "\n",
    "- Variable : 학습 및 모델 추론에 <u>필요한 변수</u>\n",
    "- Parameter : 학습을 통해 <u>찾아야 할 값</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor([1, 2, 3])\n",
    "vx = Variable(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vx.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "px = nn.Parameter(x) # 학습 가능한 파라미터 (가중치와 편향과 같은)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "print(px.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "px.requires_grad"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. torch.nn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Linear (Affine Maps)\n",
    "$f(x) = Ax + b$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear를 취할 때 정수형은 float형으로 만들어줘야 함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1898, -1.2431, -0.6487],\n",
      "        [ 1.1364,  0.1638, -1.0311]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "lin = nn.Linear(5, 3) # (input size, output size), maps from R^5 to R^3, paramters A, b\n",
    "data = Variable(torch.randn(2, 5))\n",
    "print(lin(data)) # (2x3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 비선형 함수들 (Non-Linearities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7592,  1.0220],\n",
      "        [-1.3939, -0.9680]])\n",
      "tensor([[0.0000, 1.0220],\n",
      "        [0.0000, 0.0000]])\n",
      "tensor([[-0.6406,  0.7707],\n",
      "        [-0.8840, -0.7478]])\n",
      "tensor([[0.3188, 0.7354],\n",
      "        [0.1988, 0.2753]])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "data = Variable(torch.randn(2, 2))\n",
    "print(data)\n",
    "print(F.relu(data))\n",
    "print(torch.tanh(data))\n",
    "print(torch.sigmoid(data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4116, -0.6755, -0.2887,  0.6900,  0.3158])\n",
      "tensor([0.1254, 0.0963, 0.1417, 0.3772, 0.2594])\n",
      "tensor(1.)\n",
      "tensor([-2.0766, -2.3406, -1.9537, -0.9750, -1.3492])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fw/9gdbjd851zl94gbm7f96rmcm0000gn/T/ipykernel_24617/4238806234.py:4: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  print(F.softmax(data))\n",
      "/var/folders/fw/9gdbjd851zl94gbm7f96rmcm0000gn/T/ipykernel_24617/4238806234.py:5: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  print(F.softmax(data).sum()) # Sums to 1 because it is a distribution\n",
      "/var/folders/fw/9gdbjd851zl94gbm7f96rmcm0000gn/T/ipykernel_24617/4238806234.py:6: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  print(F.log_softmax(data))\n"
     ]
    }
   ],
   "source": [
    "# Softmax is also in torch.functional\n",
    "data = Variable(torch.randn(5))\n",
    "print(data)\n",
    "print(F.softmax(data))\n",
    "print(F.softmax(data).sum()) # Sums to 1 because it is a distribution\n",
    "print(F.log_softmax(data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Containers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Module\n",
    "파이토치는 모델을 클래스처럼 다룰 수 있는데, `torch.nn.Module`을 상속받아서 부모 클래스를 초기화하는 방법\n",
    "\n",
    "선정의된 함수 `forward`에 Variable을 인자 값으로 보내면 `forward` 계산을 하면서 Parameter와의 backward 계산을 해서 가지고 있는다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(simpleNN, self).__init__() # 부모 클래스까지 초기화(부모 클래스 생성자 호출)\n",
    "        self.linear = nn.Linear(2, 2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        return self.sigmoid(self.linear(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "snn = simpleNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "simpleNN(\n",
       "  (linear): Linear(in_features=2, out_features=2, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모듈 파라미터 혹은 서브 모듈에 접근"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.2609, -0.2352],\n",
      "        [ 0.5190,  0.1624]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2174,  0.6302], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in snn.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('linear.weight', Parameter containing:\n",
      "tensor([[ 0.2609, -0.2352],\n",
      "        [ 0.5190,  0.1624]], requires_grad=True))\n",
      "('linear.bias', Parameter containing:\n",
      "tensor([-0.2174,  0.6302], requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "for param in snn.named_parameters():\n",
    "    print(param) # (name, parameters) tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.2609, -0.2352],\n",
      "        [ 0.5190,  0.1624]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in snn.named_parameters():\n",
    "    if \"weight\" in param[0]:\n",
    "        print(param[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=2, out_features=2, bias=True)\n",
      "Sigmoid()\n"
     ]
    }
   ],
   "source": [
    "for child in snn.children():\n",
    "    print(child) # module"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.7090, 0.2287]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = Variable(torch.randn(1, 2))\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5436, 0.8255]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "outputs = snn(inputs)\n",
    "print(outputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(2, 2),\n",
    "    nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2, out_features=2, bias=True)\n",
       "  (1): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7369, 0.5595]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "outputs = model(inputs)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(OrderedDict([\n",
    "    ('conv1', nn.Conv2d(1, 20, 5)),\n",
    "    ('relu1', nn.ReLU()),\n",
    "    ('conv2', nn.Conv2d(20, 64, 5)),\n",
    "    ('relu2', nn.ReLU())           \n",
    "]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function\n",
    "http://pytorch.org/docs/0.3.0/nn.html#loss-functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.CrossEntropyLoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(snn.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'params': [Parameter containing:\n",
       "   tensor([[ 0.2609, -0.2352],\n",
       "           [ 0.5190,  0.1624]], requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-0.2174,  0.6302], requires_grad=True)],\n",
       "  'lr': 0.01,\n",
       "  'momentum': 0,\n",
       "  'dampening': 0,\n",
       "  'weight_decay': 0,\n",
       "  'nesterov': False,\n",
       "  'maximize': False,\n",
       "  'foreach': None,\n",
       "  'differentiable': False}]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.param_groups"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "68ed8995195bd962de769cc9f8fcfc2ab25d676ce75fb9dc4d84a42b658673fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
